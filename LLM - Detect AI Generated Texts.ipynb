{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "# Loading data\n",
    "train_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\n",
    "test_essays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "\n",
    "# Preprocessing data\n",
    "train_texts = train_essays['text'].tolist()\n",
    "train_labels = train_essays['generated'].tolist()\n",
    "test_texts = test_essays['text'].tolist()\n",
    "\n",
    "# Tokenizing data\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/bert-base-uncased-model/bert-base-uncased\")\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding='max_length', max_length=512)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "# Converting data into TensorFlow format\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'input_ids': train_encodings['input_ids'], 'attention_mask': train_encodings['attention_mask']},\n",
    "    train_labels\n",
    "))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'input_ids': test_encodings['input_ids'], 'attention_mask': test_encodings['attention_mask']},\n",
    "))\n",
    "\n",
    "# Definining model components\n",
    "bert_layer = TFAutoModel.from_pretrained(\"/kaggle/input/bert-base-uncased-model/bert-base-uncased\", from_pt=True)\n",
    "dropout_layer = tf.keras.layers.Dropout(0.1)  \n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax')\n",
    "\n",
    "# Defining model\n",
    "input_ids = tf.keras.layers.Input(shape=(512,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.layers.Input(shape=(512,), dtype=tf.int32, name='attention_mask')\n",
    "outputs = bert_layer([input_ids, attention_mask])\n",
    "dropout_outputs = dropout_layer(outputs[1])\n",
    "output_layer_outputs = output_layer(dropout_outputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output_layer_outputs)\n",
    "\n",
    "\n",
    "# Compiling model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training model\n",
    "model.fit(train_dataset.shuffle(1000).batch(16), epochs=3)\n",
    "\n",
    "# Saving the model\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Predicting test data\n",
    "predictions = model.predict(test_dataset.batch(16))\n",
    "\n",
    "output = pd.DataFrame({'id': test_essays.id, 'generated': predictions[:, 1]})\n",
    "\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
